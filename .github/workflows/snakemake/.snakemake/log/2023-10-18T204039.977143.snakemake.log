Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Job stats:
job                  count
-----------------  -------
all                      1
get_data                 2
read_country_list        1
total                    4

Select jobs to execute...

[Wed Oct 18 20:40:40 2023]
rule get_data:
    input: ../../test/data/Agro2_co2_emissions.csv
    output: Italy_gd.txt
    jobid: 2
    reason: Missing output files: Italy_gd.txt
    wildcards: x=Italy
    resources: tmpdir=/var/folders/4l/kqxc4rwn4lj10fzv9hw4xxsr0000gn/T

[Wed Oct 18 20:40:41 2023]
Finished job 2.
1 of 4 steps (25%) done
Select jobs to execute...

[Wed Oct 18 20:40:41 2023]
rule read_country_list:
    output: country_list.txt
    jobid: 1
    reason: Missing output files: country_list.txt
    resources: tmpdir=/var/folders/4l/kqxc4rwn4lj10fzv9hw4xxsr0000gn/T

[Wed Oct 18 20:40:41 2023]
Error in rule read_country_list:
    jobid: 1
    output: country_list.txt
    shell:
        
        python -c 'from your_snakefile import read_countries;         countries = read_countries("../../test/countries.txt");         with open("country_list.txt", "w") as f:
    		f.write("\n".join(countries))'
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: .snakemake/log/2023-10-18T204039.977143.snakemake.log
