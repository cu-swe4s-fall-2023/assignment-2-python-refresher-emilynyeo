Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Job stats:
job         count
--------  -------
all             1
get_data        1
total           2

Select jobs to execute...

[Wed Oct 18 08:21:03 2023]
rule get_data:
    input: ../../test/data/Agro2_co2_emissions.csv
    output: ['Italy', 'SA']_gd.txt
    jobid: 1
    reason: Missing output files: ['Italy', 'SA']_gd.txt
    wildcards: x=['Italy', 'SA']
    resources: tmpdir=/var/folders/4l/kqxc4rwn4lj10fzv9hw4xxsr0000gn/T

[Wed Oct 18 08:21:03 2023]
Error in rule get_data:
    jobid: 1
    input: ../../test/data/Agro2_co2_emissions.csv
    output: ['Italy', 'SA']_gd.txt
    shell:
        python get_data.py ../../test/data/Agro2_co2_emissions.csv ['Italy', 'SA'] ['Italy', 'SA']_gd.txt
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: .snakemake/log/2023-10-18T082103.543889.snakemake.log
